
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Solutions for Inference &#8212; Estimating Covariance Structures and Generalised Least Squares</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/test.css?v=a80109f0" />
    <link rel="stylesheet" type="text/css" href="_static/sphericity_3d_files/rglwidgetClass-1.3.18/rgl.css?v=57907efa" />
    <link rel="stylesheet" type="text/css" href="_static/sphericity_3d_files/htmltools-fill-0.5.8.1/fill.css?v=971cc1da" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2.covariance-solutions';</script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/textures.src.js?v=9482728f"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/shadersrc.src.js?v=6ce05c17"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/buffer.src.js?v=1efca185"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/mouse.src.js?v=96f0b970"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/projection.src.js?v=98871b91"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/axes.src.js?v=3250d244"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/rglTimer.src.js?v=ac1c3151"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/pretty.src.js?v=4f2cffba"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/shaders.src.js?v=bbbdf37d"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/animation.src.js?v=74f9b9e8"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/pieces.src.js?v=280fd571"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/selection.src.js?v=5b47ed7d"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/init.src.js?v=f5bdcbbb"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/subscenes.src.js?v=42cb429d"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/controls.src.js?v=4b3dbe6f"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/draw.src.js?v=49d9cbaa"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/utils.src.js?v=56efe719"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/rglClass.src.js?v=9e593197"></script>
    <script src="_static/sphericity_3d_files/rglWebGL-binding-1.3.18/rglWebGL.js?v=8cd6f6d7"></script>
    <script src="_static/sphericity_3d_files/htmlwidgets-1.6.4/htmlwidgets.js?v=175713be"></script>
    <script src="_static/sphericity_3d_files/CanvasMatrix4-1.3.18/CanvasMatrix.src.js?v=5a2d04be"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Generalised Least Squares (GLS)" href="3.gls.html" />
    <link rel="prev" title="Estimating Covariance Structures" href="1.estimating-sigma.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Estimating Covariance Structures and Generalised Least Squares - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Estimating Covariance Structures and Generalised Least Squares - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.estimating-sigma.html">Estimating Covariance Structures</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Solutions for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.gls.html">Generalised Least Squares (GLS)</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.gls-R.html">Using GLS in <code class="docutils literal notranslate"><span class="pre">R</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="5.gls-limitations.html">Limitations of the GLS Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/estimating-covariance-gls" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/estimating-covariance-gls/issues/new?title=Issue%20on%20page%20%2F2.covariance-solutions.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2.covariance-solutions.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Solutions for Inference</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#option-1-pretend-that-boldsymbol-sigma-is-known">Option 1 - Pretend that <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is Known</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assume-hat-boldsymbol-sigma-boldsymbol-sigma">Assume <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-asymptotic-results">Use <em>Asymptotic</em> Results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-simulations">Use Simulations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#option-2-acknowledge-that-hat-boldsymbol-sigma-is-an-estimate">Option 2 - Acknowledge that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is an <em>Estimate</em></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practically-where-does-this-leave-us">Practically, Where Does This Leave Us?</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="solutions-for-inference">
<h1>Solutions for Inference<a class="headerlink" href="#solutions-for-inference" title="Link to this heading">#</a></h1>
<p>So, we find ourselves in a difficult spot. What we <em>want</em> is a framework where we can have any form of covariance structure to accurately represent the data-generating process. This would allow us to model any type of repeated measures experiment, irrespective of its complexity. However, the inferential devices used by the normal linear model simply <em>do not allow this</em>. The emphasis on <em>knowing</em> the sampling distribution of the estimates in order to calculate <span class="math notranslate nohighlight">\(p\)</span>-values and confidence intervals has backed us into a corner. Once the very specific conditions that allow these to be calculated are gone, so too is the whole inferential machinery. In a way, this demonstrates how <em>fragile</em> these methods are.</p>
<p>So, we have two options available to us. One is to simply give up and spend our whole lives restricting inference to only those datasets where the classical results to still apply. The other is that we try and find a way forward, acknowledging that <em>no</em> perfect solution is going to exist. Clearly, our plan is to push forward with the <em>second option</em>, but it is important to understand from the very beginning that we are making a <em>comprise</em>. We want to develop much better <em>models</em> that describe <em>where the data came from</em> and can make better <em>predictions</em> of future data. In order to do so, we have to accept that we have left the clean world of the normal linear model and our inference <em>will become approximate</em>. This can be an uncomfortable conclusion, but it is the reality of the situation we are in.</p>
<section id="option-1-pretend-that-boldsymbol-sigma-is-known">
<h2>Option 1 - Pretend that <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is Known<a class="headerlink" href="#option-1-pretend-that-boldsymbol-sigma-is-known" title="Link to this heading">#</a></h2>
<p>In terms of trying to push forward in spite of all these complexities, our first option is to simply assume that <em>we know</em> <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>. Of course, we <em>do not</em>, that is the whole problem we are trying to address. However, if we simply assume that we have got <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> correct, pretty much all the problems highlighted above <em>disappear</em>. In general, there are three ways this is realised in practice:</p>
<ul class="simple">
<li><p>Simply treat our estimate as the true value and ignore everything else</p></li>
<li><p>Treat our estimate as the true value, but <em>only</em> because we have enough data that the uncertainty has disappeared</p></li>
<li><p>Treat our estimate as the true value, but only for the purpose of trying to <em>simulate</em> the uncertainty using computational methods</p></li>
</ul>
<p>We will now discuss each of these in turn.</p>
<section id="assume-hat-boldsymbol-sigma-boldsymbol-sigma">
<h3>Assume <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span><a class="headerlink" href="#assume-hat-boldsymbol-sigma-boldsymbol-sigma" title="Link to this heading">#</a></h3>
<p>As a first approach, we can choose to <em>ignore</em> the problem. If we treat our estimate as <em>exactly</em> the population value, then we can carry on without any issues. So, if we take <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span> then there are no problems any more. Knowing <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> means that the covariance structure can be effectively <em>removed</em> from the data and we are back to the normal linear model. Assuming that we can do this <em>perfectly</em> (because we know <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>) all the theory around the normal linear model then applies and we are done.</p>
<p>This approach is quite <em>practically</em> appealing, because all the mess simply disappears. However, it is not without consequence. Simply ignoring the uncertainty about the value of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> means:</p>
<ul class="simple">
<li><p>The degree to which the covariance structure can be <em>removed</em> is unknown and is very unlikely to be <em>perfect</em>. As such, the degree to which the standard errors and test statistics follow a known sampling distribution is also unknown. This means we have no sense of how accurate the <span class="math notranslate nohighlight">\(p\)</span>-values or confidence intervals actually are.</p></li>
<li><p>We are pretending that degrees of freedom exist as a universal indicator of uncertainty for a single variance component, but they do not.</p></li>
<li><p>Furthermore, because we are pretending that we got <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> for free, the degrees of freedom have no correction for estimating <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>. As such, they will be <em>larger</em> than equivalent repeated measures ANOVA models.</p></li>
</ul>
</section>
<section id="use-asymptotic-results">
<h3>Use <em>Asymptotic</em> Results<a class="headerlink" href="#use-asymptotic-results" title="Link to this heading">#</a></h3>
<p>As a second approach, we can choose to <em>acknowledge</em> the problem, but assume that it does not apply to us. As discussed earlier, most of the issues here arise in <em>small samples</em>. This is because the uncertainty around <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> will be much greater. We see this with the use of the <span class="math notranslate nohighlight">\(t\)</span>-distribution in the normal linear model. Small sample means smaller degrees of freedom, which means a wider scaled <span class="math notranslate nohighlight">\(\chi^{2}(\nu)\)</span> distribution and a null <span class="math notranslate nohighlight">\(t\)</span>-distribution with heavier tails than a standard normal. As the sample gets <em>larger</em>, most of this disappears. The scaled <span class="math notranslate nohighlight">\(\chi^{2}(\nu)\)</span> collapses to a single point and the <span class="math notranslate nohighlight">\(t\)</span>-statistic becomes a <span class="math notranslate nohighlight">\(z\)</span>-statistics, At this point we no longer need uncertainty in the form of degrees of freedom. The null <span class="math notranslate nohighlight">\(z \sim \mathcal{N}(0,1)\)</span> is not parameterised by degrees of freedom because its shape is <em>fixed</em> rather than <em>dynamic</em>. So, the solution here is to calculate <span class="math notranslate nohighlight">\(z\)</span>-statistics instead of <span class="math notranslate nohighlight">\(t\)</span>-statistics and <span class="math notranslate nohighlight">\(\chi^{2}\)</span> statistics instead of <span class="math notranslate nohighlight">\(F\)</span>-statistics. We can then refer to null distributions <em>without</em> error degrees of freedom and claim that the tests are <em>asymptotically</em> correct. In other words, these results are correct, so long as the sample size is large enough that our uncertainty around <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> has effectively <em>vanished</em>. In other words, we can treat <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span> not because we <em>know</em> it already, but because we have so much data that this is <em>effectively</em> true.</p>
<p>Compared to the earlier possibility, this approach has a certain <em>statistical purity</em> to it. We do not need to pretend degrees of freedom still exist nor pretend that any of the small sample theory still applies. We can also ignore the whole idea of the sampling distribution of the denominator because, if we have enough data, <em>this does not matter</em>. So we do not need to pretend it has a certain form, we can simply ignore it. However, there are still some clear issues here:</p>
<ul class="simple">
<li><p>We need to be comfortable assuming that our <span class="math notranslate nohighlight">\(n\)</span> is <em>large-enough</em> for this to work, but this is an <em>unanswerable</em> question (see box below).</p></li>
<li><p>We need to be comfortable with the idea of dismissing uncertainty in the estimation of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> as negligible.</p></li>
<li><p>In small samples this will result in inference that is <em>optimistic</em>. However, the open use of asymptotic tests already embeds this as a caution. As such, we shift the uncertainty in small samples from a mathematical concern to an <em>interpretative</em> concern. If we distrust these results as samples get smaller, we are doing the job of adjusting our inference accordingly.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">How Large is “Large”?</p>
<p>If we want to lean on asymptotic theory, the obvious question is “how big does <span class="math notranslate nohighlight">\(n\)</span> need to be?”. The problem is that the definition is based on a <em>limit</em>, so it says that the approximation gets better and better as <span class="math notranslate nohighlight">\(n\)</span> moves towards infinity. For our purpose, <span class="math notranslate nohighlight">\(n\)</span> is the <em>number of subjects</em>, rather than the total amount of data. So, the answer is not that there is some magic sample size that is suddenly large enough, the answer is that the approximation will get better the larger <span class="math notranslate nohighlight">\(n\)</span> becomes. The question then is more about what our tolerance for error is. The point of the asymptotic theory is to say that the error that comes from estimation becomes more negligible as <span class="math notranslate nohighlight">\(n\)</span> grows, as does the penalty for estimating <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> from the data. So, unfortunately, there is <em>no honest numeric answer to this question</em>. The way to think about it is as a <em>degree of comfort</em>. If you are have <span class="math notranslate nohighlight">\(n = 5\)</span>, you should probably feel <em>very uncomfortable</em>, whereas <span class="math notranslate nohighlight">\(n = 50\)</span> should probably make you feel <em>cautious</em>. If you have <span class="math notranslate nohighlight">\(n = 100\)</span>, you should feel <em>optimistic</em> and if you have <span class="math notranslate nohighlight">\(n = 200\)</span> you should probably be feeling <em>fairly confident</em>. As <span class="math notranslate nohighlight">\(n\)</span> increases beyond that, you should probable feel <em>perfectly fine</em> about this approach. These are only ballpark figures, but the point is really to think of <span class="math notranslate nohighlight">\(n\)</span> as a <em>continuum of comfort</em>, rather than as a <em>threshold</em>.</p>
</div>
</section>
<section id="use-simulations">
<h3>Use Simulations<a class="headerlink" href="#use-simulations" title="Link to this heading">#</a></h3>
<p>As a third approach, we can again choose to <em>acknowledge</em> the problem, but assume that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is a close-enough proxy to <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> so we can use it to <em>simulate</em> its uncertainty across multiple samples. So, this involves assuming <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span>, but only insofar as assuming that our estimate is close enough to define a <em>plasuible world</em> for simulation. We do not assume that the uncertainty in estimating <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is negligible. In fact, the whole point of the simulations is to <em>measure it</em>.</p>
<p>The advantage here is that we do not assume the uncertainty around estimating <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> has a particular shape. Instead, we let the simulations build the relevant sampling distributions over its many iterations. This neither requires assuming that the classical results still hold, nor requires enough data so that all these problems disappear. Instead, we use the power of the <em>computer</em> to find a solution. This gets us into the world of <em>resampling methods</em>, which we encountered briefly last semester in the form of the <em>permutation test</em>. For the general problem of deriving a null distribution under an arbitrary covariance structure, the <em>parametric bootstrap</em> is most commonly employed. In this method we:</p>
<ol class="arabic simple">
<li><p>Treat a fitted <em>null model</em> as the “truth”.</p></li>
<li><p>Use this fitted model to simulate new data.</p></li>
<li><p>Refit the model to the simulated dataset and save a copy of the test statistic.</p></li>
<li><p>Over many repeats of 2 and 3, build up a <em>distribution</em> of the test statistic under the null.</p></li>
<li><p>Calculate the <span class="math notranslate nohighlight">\(p\)</span>-value and confidence intervals from this distribution.</p></li>
</ol>
<p>So this requires <em>zero</em> theory about the distribution of the sampling distributions. The uncertainty comes through naturally as part of the simulation and we can get a <span class="math notranslate nohighlight">\(p\)</span>-value irrespective of the form of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>. There are no <em>degrees of freedom</em> here as a parameter of a sampling distribution because the distribution that is built does not even need to be mathematically tractable[^tractable-foot]. So this has some distinct advantages because we can get rid of much of the difficult approximation needed in classical approaches. However, there are still trade-offs:</p>
<ul class="simple">
<li><p>Computational burden is high, as calculating a single <span class="math notranslate nohighlight">\(p\)</span>-value can be a long process depending upon the complexity of refitting the model.</p></li>
<li><p>Fundamentally, we have to assume that our models is <em>close enough</em> to the truth for this to work. Not only in terms of the covariance structure, but also in terms of the assumed population distribution. This is why this is a <em>parametric</em> bootstrap, rather than a <em>non-parametric</em> procedure.</p></li>
<li><p>Assumptions about the accuracy of the covariance structure will improve with larger samples, meaning we can trust the simulations more. However, the more data we have the more <em>asymptotic</em> theory takes over, so the need for simulation becomes more questionable. That being said, simulation is useful for that unknown middle-ground between samples that are too small for <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> to be reliable and the point where asymptotic theory takes over.</p></li>
</ul>
</section>
</section>
<section id="option-2-acknowledge-that-hat-boldsymbol-sigma-is-an-estimate">
<h2>Option 2 - Acknowledge that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is an <em>Estimate</em><a class="headerlink" href="#option-2-acknowledge-that-hat-boldsymbol-sigma-is-an-estimate" title="Link to this heading">#</a></h2>
<p>All the methods above were variations on a theme where, in one way or another, we assume that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span>. This was either because we were ignoring the problem, assuming that we had enough data so the problem disappeared, or assuming that our estimate was close-enough to the population value to be used for simulation. However, another option is to avoid making this assumption entirely and fully accept that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is an estimate. Once we do that, we acknowledge that there is some degree of uncertainty in its value and, without having any of way of deriving this uncertainty exactly, we need to correct for it.</p>
<p>Methods that take this approach do so by creating <em>fictitious</em> degrees of freedom that allow a <span class="math notranslate nohighlight">\(p\)</span>-value to be calculated that has been approximately adjusted for the uncertainty. The way this is typically done is that</p>
<ol class="arabic simple">
<li><p>The test statistic is formed in the usual way</p></li>
<li><p>The properties of the fitted model are used <em>analytically</em> to approximate the mean and the variance of the test statistic over repeated samples</p></li>
<li><p>The mean and variance are then used to solve for the parameters of the null distribution, producing what are known as <em>effective degrees of freedom</em></p></li>
<li><p>Those effective degrees of freedom are used to calculate a <span class="math notranslate nohighlight">\(p\)</span>-value and confidence intervals</p></li>
</ol>
<p>As an example, say we formed a <span class="math notranslate nohighlight">\(t\)</span>-statistic from our model. We know that this is a statistic with an unknown null distribution, so we will call it <span class="math notranslate nohighlight">\(t^{\star}\)</span>. We can use information in the model alongside the value of <span class="math notranslate nohighlight">\(t^{\star}\)</span> to <em>approximate</em> <span class="math notranslate nohighlight">\(\text{Var}(t^{\star})\)</span>[^analytic-foot]. Once we have this, we simply note that the variance of a <span class="math notranslate nohighlight">\(t\)</span>-distribution can be expressed as <span class="math notranslate nohighlight">\(\frac{\nu}{\nu - 2}\)</span>. So, we can use our approximate variance value to solve for <span class="math notranslate nohighlight">\(\nu\)</span>. This gives us the <em>effective degrees of freedom</em> of this <span class="math notranslate nohighlight">\(t\)</span>-distribution and we can calculate a <span class="math notranslate nohighlight">\(p\)</span>-value. In essence, we have approximated capturing <em>universal uncertainty</em> in the same way that traditional degrees of freedom do, but within a context where this definition is no longer applicable.</p>
<p>We have already seen an example of this approach in terms of the <em>non-sphericity corrections</em> that can be applied to a repeated measures ANOVA. Similar methods for more general models include the Satterthwaite degrees of freedom and the Kenward-Rogers degrees of freedom, which also contains a <em>bias correction</em> for the fact that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is a <em>biased</em> estimate of the true covariance structure.</p>
<p>This method is perhaps more appealing than simply pretending there is no problem because it tried to accommodate small sample adjustments and uncertainty, though it also comes with some consequences:</p>
<ul class="simple">
<li><p>We are assuming that the true null distribution only differs from known null distributions (such as the <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(F\)</span>) by its width, but not the general shape.</p></li>
<li><p>This still remains an <em>approximation</em>, though it should behave better in smaller samples when degrees of freedom become more necessary.</p></li>
<li><p>Degrees of freedom can become fractional and no longer have a clear theoretical grounding. They are more devices to encode “tail-heaviness” within the familiar language of <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(F\)</span> distributions.</p></li>
</ul>
<p>In fact, we already saw an example of this last week in terms of the <em>non-sphericity corrections</em>.</p>
</section>
<section id="practically-where-does-this-leave-us">
<h2>Practically, Where Does This Leave Us?<a class="headerlink" href="#practically-where-does-this-leave-us" title="Link to this heading">#</a></h2>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1.estimating-sigma.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Estimating Covariance Structures</p>
      </div>
    </a>
    <a class="right-next"
       href="3.gls.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Generalised Least Squares (GLS)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#option-1-pretend-that-boldsymbol-sigma-is-known">Option 1 - Pretend that <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is Known</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assume-hat-boldsymbol-sigma-boldsymbol-sigma">Assume <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-asymptotic-results">Use <em>Asymptotic</em> Results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-simulations">Use Simulations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#option-2-acknowledge-that-hat-boldsymbol-sigma-is-an-estimate">Option 2 - Acknowledge that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is an <em>Estimate</em></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practically-where-does-this-leave-us">Practically, Where Does This Leave Us?</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>