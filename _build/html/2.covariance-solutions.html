
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Solutions for Inference &#8212; Estimating Covariance Structures and Generalised Least Squares</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/test.css?v=a80109f0" />
    <link rel="stylesheet" type="text/css" href="_static/sphericity_3d_files/rglwidgetClass-1.3.18/rgl.css?v=57907efa" />
    <link rel="stylesheet" type="text/css" href="_static/sphericity_3d_files/htmltools-fill-0.5.8.1/fill.css?v=971cc1da" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2.covariance-solutions';</script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/textures.src.js?v=9482728f"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/shadersrc.src.js?v=6ce05c17"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/buffer.src.js?v=1efca185"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/mouse.src.js?v=96f0b970"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/projection.src.js?v=98871b91"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/axes.src.js?v=3250d244"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/rglTimer.src.js?v=ac1c3151"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/pretty.src.js?v=4f2cffba"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/shaders.src.js?v=bbbdf37d"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/animation.src.js?v=74f9b9e8"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/pieces.src.js?v=280fd571"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/selection.src.js?v=5b47ed7d"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/init.src.js?v=f5bdcbbb"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/subscenes.src.js?v=42cb429d"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/controls.src.js?v=4b3dbe6f"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/draw.src.js?v=49d9cbaa"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/utils.src.js?v=56efe719"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/rglClass.src.js?v=9e593197"></script>
    <script src="_static/sphericity_3d_files/rglWebGL-binding-1.3.18/rglWebGL.js?v=8cd6f6d7"></script>
    <script src="_static/sphericity_3d_files/htmlwidgets-1.6.4/htmlwidgets.js?v=175713be"></script>
    <script src="_static/sphericity_3d_files/CanvasMatrix4-1.3.18/CanvasMatrix.src.js?v=5a2d04be"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Generalised Least Squares (GLS)" href="3.gls.html" />
    <link rel="prev" title="Estimating Covariance Structures" href="1.estimating-sigma.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Estimating Covariance Structures and Generalised Least Squares - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Estimating Covariance Structures and Generalised Least Squares - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.estimating-sigma.html">Estimating Covariance Structures</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Solutions for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.gls.html">Generalised Least Squares (GLS)</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.gls-R.html">Using GLS in <code class="docutils literal notranslate"><span class="pre">R</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="5.gls-limitations.html">Limitations of the GLS Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/estimating-covariance-gls" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/estimating-covariance-gls/issues/new?title=Issue%20on%20page%20%2F2.covariance-solutions.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2.covariance-solutions.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Solutions for Inference</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#option-1-pretend-that-boldsymbol-sigma-is-known">Option 1 - Pretend that <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is Known</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-assume-hat-boldsymbol-sigma-boldsymbol-sigma">a. Assume <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-use-asymptotic-results">b. Use <em>Asymptotic</em> Results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#option-2-acknowledge-that-hat-boldsymbol-sigma-is-an-estimate">Option 2 - Acknowledge that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is an <em>Estimate</em></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practically-where-does-this-leave-us">Practically, Where Does This Leave Us?</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="solutions-for-inference">
<h1>Solutions for Inference<a class="headerlink" href="#solutions-for-inference" title="Link to this heading">#</a></h1>
<p>Given what we discussed in the previous part of this lesson, we are in a difficult situation. What we <em>want</em> is a framework where we can have any form of covariance structure to accurately represent the data-generating process. This would allow us to model any type of repeated measures experiment, irrespective of its complexity. However, the inferential devices used by the normal linear model simply <em>do not allow this</em>. The emphasis on <em>knowing</em> the sampling distribution of the estimates in order to calculate <span class="math notranslate nohighlight">\(p\)</span>-values and confidence intervals has backed us into a corner. Once the very specific conditions that allow these to be calculated are gone, so too is the whole inferential machinery. In a way, this demonstrates how <em>fragile</em> these methods are.</p>
<p>So, we have two options available to us. One is to simply give up and spend our whole lives restricting inference to only those datasets where the classical results to still apply. The other is that we try and find a way forward. Clearly, our plan is to push forward with the <em>second option</em>, but it is important to understand from the very beginning that we are making a <em>comprise</em>. We want to develop much better <em>models</em> that describe <em>where the data came from</em>. In order to do so, we have to accept that we have left the clean world of the normal linear model behind and our inference <em>will become approximate</em>. This can be an uncomfortable conclusion, but it is the reality of the situation we are in.</p>
<section id="option-1-pretend-that-boldsymbol-sigma-is-known">
<h2>Option 1 - Pretend that <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is Known<a class="headerlink" href="#option-1-pretend-that-boldsymbol-sigma-is-known" title="Link to this heading">#</a></h2>
<p>In terms of trying to push forward, in spite of all these complexities, our first option is to simply assume that <em>we know</em> <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>. Of course, we <em>do not</em>, that is the whole problem we are trying to address. However, if we simply assume that we have got <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> correct, pretty much all the problems highlighted previously <em>disappear</em>. In general, there are two ways this is realised in practice. We can choose to:</p>
<ol type="a">
  <li>Treat our estimate as the true value and ignore everything else</li>
  <li>Treat our estimate as the true value, but <i>only</i> because we have enough data that the uncertainty has disappeared</li>
</ol>
<p>We will now discuss each of these in more detail.</p>
<section id="a-assume-hat-boldsymbol-sigma-boldsymbol-sigma">
<h3>a. Assume <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span><a class="headerlink" href="#a-assume-hat-boldsymbol-sigma-boldsymbol-sigma" title="Link to this heading">#</a></h3>
<p>As a first approach, we can choose to <em>ignore</em> the problem. If we treat our estimate as <em>exactly</em> the population value, then we can carry on without any issues. As we will come to see, methods that allow for a more general covariance matrix do so by <em>removing</em> this structure from the data. Taking <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span> means that the covariance structure can be <em>perfectly removed</em> and we are back to the normal linear model. All the original inferential theory then applies and we are done. So, this approach is quite <em>practically</em> appealing because all the mess simply disappears.</p>
<p>However, this is not without consequence. Simply ignoring the uncertainty about the value of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> means:</p>
<ul class="simple">
<li><p>The degree to which the covariance structure can be <em>removed</em> is unknown and is very unlikely to be <em>perfect</em>. As such, the degree to which the standard errors and test statistics follow a known sampling distribution is also unknown. This means we have no sense of how accurate the <span class="math notranslate nohighlight">\(p\)</span>-values or confidence intervals actually are.</p></li>
<li><p>We are pretending that degrees of freedom exist as a universal indicator of uncertainty for a single variance component, but they do not.</p></li>
<li><p>Because we are pretending that we got <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> for free, the degrees of freedom have no correction for estimating <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>. As such, they will be <em>larger</em> than equivalent repeated measures ANOVA models.</p></li>
</ul>
</section>
<section id="b-use-asymptotic-results">
<h3>b. Use <em>Asymptotic</em> Results<a class="headerlink" href="#b-use-asymptotic-results" title="Link to this heading">#</a></h3>
<p>As a second approach, we can choose to <em>acknowledge</em> the problem, but assume that it does not apply to us. As discussed earlier, most of the issues here arise in <em>small samples</em> because the uncertainty around <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is much greater. We see this with the <span class="math notranslate nohighlight">\(t\)</span>-distribution in the normal linear model. Small sample means smaller degrees of freedom, which means a wider scaled <span class="math notranslate nohighlight">\(\chi^{2}(\nu)\)</span> distribution and a null <span class="math notranslate nohighlight">\(t\)</span>-distribution with heavier tails. As the sample gets <em>larger</em>, most of the complexity disappears. The scaled <span class="math notranslate nohighlight">\(\chi^{2}(\nu)\)</span> collapses to a single point and the <span class="math notranslate nohighlight">\(t\)</span>-statistic becomes a <span class="math notranslate nohighlight">\(z\)</span>-statistic. At this point we no longer need degrees of freedom because the null <span class="math notranslate nohighlight">\(z \sim \mathcal{N}(0,1)\)</span> has a <em>fixed</em> rather than <em>dynamic</em> shape. So, the solution here is to simply calculate <span class="math notranslate nohighlight">\(z\)</span>-statistics instead of <span class="math notranslate nohighlight">\(t\)</span>-statistics<a class="footnote-reference brackets" href="#chisq-foot" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. We can then refer to null distributions <em>without</em> degrees of freedom and claim that the tests are <em>asymptotically</em> correct. In other words, these results are correct, so long as the sample size is large enough that our uncertainty around <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is now <em>negligible</em>. In other words, we can treat <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span> not because we <em>know</em> it already, but because we have so much data that this is <em>effectively</em> true.</p>
<p>Compared to possibility <strong>a</strong>, this approach has a certain <em>statistical purity</em> to it. We do not need to pretend degrees of freedom still exist nor pretend that any of the small sample theory still applies. We can also ignore the whole idea of the sampling distribution of the denominator because, if we have enough data, <em>this does not matter</em>. So we do not need to pretend it has a certain form, we can simply ignore it. However, there are still some clear issues here:</p>
<ul class="simple">
<li><p>We need to be comfortable assuming that our <span class="math notranslate nohighlight">\(n\)</span> is <em>large-enough</em> for this to work, but this is an <em>unanswerable</em> question (see box below).</p></li>
<li><p>We need to be comfortable with the idea of dismissing uncertainty in the estimation of <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> as negligible.</p></li>
<li><p>In small samples this will result in inference that is <em>optimistic</em>. However, the open use of asymptotic tests already embeds this as a caution. As such, adjusting inference for small samples becomes an <em>interpretative</em> concern, rather than a mathematical one.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">How Large is “Large”?</p>
<p>If we want to lean on asymptotic theory, the obvious question is “how big does <span class="math notranslate nohighlight">\(n\)</span> need to be?”. The problem is that the definition is based on a <em>limit</em>, so it says that the approximation gets better and better as <span class="math notranslate nohighlight">\(n\)</span> moves towards infinity. For our purpose, <span class="math notranslate nohighlight">\(n\)</span> is the <em>number of subjects</em>, rather than the total amount of data. So, the answer is not that there is some magic sample size that is suddenly large enough, the answer is that the approximation will get better the larger <span class="math notranslate nohighlight">\(n\)</span> becomes. The question then is more about what our tolerance for error is. The point of the asymptotic theory is to say that the error that comes from estimation becomes more negligible as <span class="math notranslate nohighlight">\(n\)</span> grows, as does the penalty for estimating <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> from the data. So, unfortunately, there is <em>no honest numeric answer to this question</em>. The way to think about it is as a <em>degree of comfort</em>. If you are have <span class="math notranslate nohighlight">\(n = 5\)</span>, you should probably feel <em>very uncomfortable</em>, whereas <span class="math notranslate nohighlight">\(n = 50\)</span> should probably make you feel <em>cautious</em>. If you have <span class="math notranslate nohighlight">\(n = 100\)</span>, you should feel <em>optimistic</em> and if you have <span class="math notranslate nohighlight">\(n = 200\)</span> you should probably be feeling <em>fairly confident</em>. As <span class="math notranslate nohighlight">\(n\)</span> increases beyond that, you should probable feel <em>perfectly fine</em> about this approach. These are only ballpark figures, but the point is really to think of <span class="math notranslate nohighlight">\(n\)</span> as a <em>continuum of comfort</em>, rather than as a <em>threshold</em>.</p>
</div>
</section>
</section>
<section id="option-2-acknowledge-that-hat-boldsymbol-sigma-is-an-estimate">
<h2>Option 2 - Acknowledge that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is an <em>Estimate</em><a class="headerlink" href="#option-2-acknowledge-that-hat-boldsymbol-sigma-is-an-estimate" title="Link to this heading">#</a></h2>
<p>The methods above were both variations on a theme where, in one way or another, we assume that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span>. This was either because we were ignoring the problem, or because we were assuming that we had enough data so the problem disappeared. However, another option is to avoid making this assumption entirely and fully accept that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is an estimate. Once we do that, we acknowledge that there is some degree of uncertainty in its value and, without having any of way of deriving this uncertainty exactly, we need to correct for it.</p>
<p>Methods that take this approach do so by creating <em>fictitious</em> degrees of freedom that allow a <span class="math notranslate nohighlight">\(p\)</span>-value to be calculated that has been approximately adjusted for the uncertainty. The way this is typically done is that</p>
<ol class="arabic simple">
<li><p>The test statistic is formed in the usual way</p></li>
<li><p>The properties of the fitted model are used <em>analytically</em> to approximate the mean and the variance of the test statistic over repeated samples</p></li>
<li><p>The mean and variance are then used to solve for the parameters of the null distribution, producing what are known as <em>effective degrees of freedom</em></p></li>
<li><p>Those effective degrees of freedom are used to calculate a <span class="math notranslate nohighlight">\(p\)</span>-value and confidence intervals</p></li>
</ol>
<p>As an example, say we formed a <span class="math notranslate nohighlight">\(t\)</span>-statistic from our model. We know that this is a statistic with an unknown null distribution, so we will call it <span class="math notranslate nohighlight">\(t^{\star}\)</span>. We can use information in the model alongside the value of <span class="math notranslate nohighlight">\(t^{\star}\)</span> to <em>approximate</em> <span class="math notranslate nohighlight">\(\text{Var}(t^{\star})\)</span><a class="footnote-reference brackets" href="#analytic-foot" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>. Once we have this, we simply note that the variance of a <span class="math notranslate nohighlight">\(t\)</span>-distribution can be expressed as <span class="math notranslate nohighlight">\(\frac{\nu}{\nu - 2}\)</span>. So, we can use our approximate variance value to solve for <span class="math notranslate nohighlight">\(\nu\)</span>. This gives us the <em>effective degrees of freedom</em> of this <span class="math notranslate nohighlight">\(t\)</span>-distribution and we can calculate a <span class="math notranslate nohighlight">\(p\)</span>-value. In essence, we have approximated capturing <em>universal uncertainty</em> in the same way that traditional degrees of freedom do, but within a context where this definition is no longer applicable.</p>
<p>This method is perhaps more appealing than simply pretending there is no problem because it at least tries to accommodate small sample adjustments. However, this also comes with some consequences:</p>
<ul class="simple">
<li><p>We are assuming that the true null distribution only differs from known null distributions (such as the <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(F\)</span>) by its width, but not the general shape. This is potential quite a big assumption to make.</p></li>
<li><p>Although <span class="math notranslate nohighlight">\(p\)</span>-values can still be reported within the familiar language of <span class="math notranslate nohighlight">\(t\)</span>/<span class="math notranslate nohighlight">\(F\)</span>-statistics, we must not forget that this remains an <em>approximation</em>.</p></li>
<li><p>In principle, this should behave better in smaller samples compared to the naive degrees of freedom discussed earlier. However, this behaviour is ultimately <em>unkown</em>.</p></li>
<li><p>These degrees of freedom can become fractional and no longer have a clear theoretical grounding. They are more devices to encode “tail-heaviness” within the familiar language of <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(F\)</span> distributions.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Effective Degrees of Freedom Methods</p>
<p>Although the term <em>effective degrees of freedom</em> may be new, we already saw an example of this approach last week in terms of the <em>non-sphericity corrections</em> applied to a repeated measures ANOVA. Similar methods for more general models include the Satterthwaite degrees of freedom and the Kenward-Rogers degrees of freedom. This latter method also contains a <em>bias correction</em> for <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span>, which should make it more accurate but can come with a severe computational cost, depending upon the model.</p>
</div>
</section>
<section id="practically-where-does-this-leave-us">
<h2>Practically, Where Does This Leave Us?<a class="headerlink" href="#practically-where-does-this-leave-us" title="Link to this heading">#</a></h2>
<p>Given all the discussion above, what are we supposed to do <em>practically</em>? Although in principle we could simply decide which of the above methods sounds most justifiable to us, in reality we are bound by which of these methods have been implemented in software. So, even if we wish for a consistent inferential framework using our preferred method, we will be restricted by what is available to us. This is where more curated software like SPSS, SAS or STATA has an advantage, because there will be a centralised decision about which method(s) to provide and these will be provided <em>consistently</em>. For instance, SPSS prefers effective degrees of freedom, whereas STATA prefers asymptotic tests. The disadvantage is that if you personally disagree with this approach, there is little you can do. The advantage of an ecosystem like <code class="docutils literal notranslate"><span class="pre">R</span></code> is <em>choice</em>, but that choice can itself become a burden.</p>
<p>Below is a table that will not make complete sense right now, but indicates which of the above options are available when using the functions <code class="docutils literal notranslate"><span class="pre">gls()</span></code>, <code class="docutils literal notranslate"><span class="pre">lme()</span></code> and <code class="docutils literal notranslate"><span class="pre">lmer()</span></code> to fit different models in <code class="docutils literal notranslate"><span class="pre">R</span></code>. These are labelled in terms of the naive <span class="math notranslate nohighlight">\(t\)</span>/<span class="math notranslate nohighlight">\(F\)</span>-statistics, asymptotic <span class="math notranslate nohighlight">\(z\)</span>/<span class="math notranslate nohighlight">\(\chi^{2}\)</span>-statistics or corrected <span class="math notranslate nohighlight">\(t\)</span>/<span class="math notranslate nohighlight">\(F\)</span>-statistics using effective degrees of freedom. Note, however, that even when using effective degrees of freedom, there can be difference in terms of the calculation method employed.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model function</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">summary()</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">anova()</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">Anova()</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">emmeans()</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">gls()</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(t\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(F\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\chi^{2}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(t\)</span>/<span class="math notranslate nohighlight">\(F\)</span> <br> <span class="math notranslate nohighlight">\(z\)</span>/<span class="math notranslate nohighlight">\(\chi^{2}\)</span> <br> <span class="math notranslate nohighlight">\(t\)</span>/<span class="math notranslate nohighlight">\(F\)</span> (corr.)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">lme()</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(t\)</span> (corr.)</p></td>
<td><p><span class="math notranslate nohighlight">\(F\)</span> (corr.)</p></td>
<td><p><span class="math notranslate nohighlight">\(\chi^{2}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(z\)</span>/<span class="math notranslate nohighlight">\(\chi^{2}\)</span> <br> <span class="math notranslate nohighlight">\(t\)</span>/<span class="math notranslate nohighlight">\(F\)</span> (corr.)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">lmer()</span></code></p></td>
<td><p><strong>none</strong></p></td>
<td><p><strong>none</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\chi^{2}\)</span> <br> <span class="math notranslate nohighlight">\(F\)</span> (corr.)</p></td>
<td><p><span class="math notranslate nohighlight">\(z\)</span>/<span class="math notranslate nohighlight">\(\chi^{2}\)</span> <br> <span class="math notranslate nohighlight">\(t\)</span>/<span class="math notranslate nohighlight">\(F\)</span> (corr.)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">lmer()</span></code> + <code class="docutils literal notranslate"><span class="pre">lmerTest</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(t\)</span> (corr.)</p></td>
<td><p><span class="math notranslate nohighlight">\(F\)</span> (corr.)</p></td>
<td><p><span class="math notranslate nohighlight">\(\chi^{2}\)</span> <br> <span class="math notranslate nohighlight">\(F\)</span> (corr.)</p></td>
<td><p><span class="math notranslate nohighlight">\(z\)</span>/<span class="math notranslate nohighlight">\(\chi^{2}\)</span> <br> <span class="math notranslate nohighlight">\(t\)</span>/<span class="math notranslate nohighlight">\(F\)</span> (corr.)</p></td>
</tr>
</tbody>
</table>
</div>
<p>As you can see, this is all a bit of a mess. Part of the problem is that there is no <em>single</em> agreed-upon solution. As discussed above, each of these methods has caveats and are all <em>approximations</em> to an inferential framework that no longer fits. Indeed, by default the <code class="docutils literal notranslate"><span class="pre">lme4</span></code> package (used to fit mixed-effects models) refuses to even play this game and gives you <em>no <span class="math notranslate nohighlight">\(p\)</span>-values at all</em>. As such, the reality is that it is up to the authors of each package to implement the methods they agree with. This has resulted in an awkward fragmentation of methods, depending upon the functions you are working with. Ultimately, this exposes the uncomfortable truth about what we are trying to do here and makes it much more difficult to use a single inferential framework <em>consistently</em>. We will be exploring all these functions and all these options across the next few weeks, so make sure you come back to this table when you want to review which methods are associated with each function. For now, <em>even before we have discussed a single model</em>, we can see that our goal is a highly uncertain and controversial one.</p>
<aside class="topic">
<p class="topic-title">What do you now know?</p>
<p>In this section, we have explored … . After reading this section, you should have a good sense of :</p>
<ul class="simple">
<li><p>…</p></li>
<li><p>…</p></li>
<li><p>…</p></li>
</ul>
</aside>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="chisq-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>The same principle can be applied to the <span class="math notranslate nohighlight">\(F\)</span>-statistic. Because an <span class="math notranslate nohighlight">\(F\)</span> is a ratio of two variance terms, the <span class="math notranslate nohighlight">\(F\)</span>-distribution is derived from the ratio of two <span class="math notranslate nohighlight">\(\chi^{2}\)</span> random variates. When the denominator is taken as a constant, this is just a <em>scaled</em> version of the numerator (exactly the same as with the <span class="math notranslate nohighlight">\(t\)</span>-statistic). So this just becomes a scaled <span class="math notranslate nohighlight">\(\chi^{2}\)</span> and we can use a null <span class="math notranslate nohighlight">\(\chi^{2}\)</span> distribution for inference.</p>
</aside>
<aside class="footnote brackets" id="analytic-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>These methods are complicated and we do not need to concern ourselves with them. If your are really curious, you can look-up the Taylor Expansion.</p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1.estimating-sigma.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Estimating Covariance Structures</p>
      </div>
    </a>
    <a class="right-next"
       href="3.gls.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Generalised Least Squares (GLS)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#option-1-pretend-that-boldsymbol-sigma-is-known">Option 1 - Pretend that <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is Known</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-assume-hat-boldsymbol-sigma-boldsymbol-sigma">a. Assume <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}} = \boldsymbol{\Sigma}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-use-asymptotic-results">b. Use <em>Asymptotic</em> Results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#option-2-acknowledge-that-hat-boldsymbol-sigma-is-an-estimate">Option 2 - Acknowledge that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Sigma}}\)</span> is an <em>Estimate</em></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practically-where-does-this-leave-us">Practically, Where Does This Leave Us?</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>